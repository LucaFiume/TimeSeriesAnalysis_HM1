---
title: "Time Series Forecasting - Homework 1"
subtitle: Group 5
output:
  html_document:
    toc: yes
    toc_depth: '4'
    df_print: paged
  html_notebook:
    toc: yes
    toc_float: yes
    toc_collapsed: yes
    toc_depth: 4
---

```{r libraries, include=FALSE}
library(fBasics)
library(forecast)
```

```{r loading-dataset, include=FALSE}
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data<-read.csv("Homework_1_DATA.csv",header=TRUE,sep=";",dec=",")
```

## First view of the data
Analyzing data.
Showing the head and tail of the dataset
```{r head, echo=FALSE}
head(data)
```

```{r tail, echo=FALSE}
tail(data)
```
Checking the length of each series.
```{r series-length, echo=FALSE}
for (c in 1:ncol(data)){
  series_length <- length(which(!is.na(data[,c])))
  print(paste("Series", c, "has", series_length, "data points."))
}
```

Assignation of series.
```{r assignation}
series1=data[,1] [1:300]
series2=data[,2] [1:300]
series3=data[,3] [1:300]
series4=data[,4] [1:300]
series5=data[,5] [1:2000]
series6=data[,6]
series7=data[,7]
```

## Series 1

### Graphical exploration (first moment - mean)

```{r}
y<-series1    # from now, "y" is the data we are going to work with

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # plot the series, its acf and pacf together
ts.plot(y)   
acf(y)
pacf(y)
```


### Checking for Normality (graphically)
```{r}
#Checking for normality graphically
hist(y,prob=T,ylim=c(0,0.6),xlim=c(mean(y)-3*sd(y),mean(y)+3*sd(y)),col="red")
lines(density(y),lwd=2)
mu<-mean(y)
sigma<-sd(y)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

### Graphical exploration (second moment - variance)
```{r}
# C.	Testing for STRICT WHITE NOISE

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # analysis of the squared data
ts.plot(y^2)   
acf(y^2)
pacf(y^2)
```


### Computing basic stats

```{r}
mean(y) # compute basic statistics
sd(y)
skewness(y)
kurtosis(y,method=c("moment"))  
```

### Checking for CS

```{r}
# formal unit root test (Augmented Dickey Fuller test). Testing for stationarity.
# Ho: the process is not stationary. We need, at least, a unit root
# H1: the process is stationary. We have to check different models (lags)
ndiffs(y, alpha=0.05, test=c("adf")) # number of regular differences?
```


### Checking for Normality
```{r}
# formal normality test
# Ho: the data is normally distributed
# H1: the data is not normally distributed
shapiro.test(y)
```

### Checking for correlation
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test (y, lag = 20, type="Ljung")  # Null: ro1=.=ro20=0
```

### Checking for correlation in the second moment
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test(y^2,lag=20, type="Ljung")    # Null: ro1=.=ro20=0
```


## Series 2

### Graphical exploration (first moment - mean)

```{r}
y<-series2    # from now, "y" is the data we are going to work with

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # plot the series, its acf and pacf together
ts.plot(y)   
acf(y)
pacf(y)
```
**Observations**:  
- TS (stochastic process) looks no stationary in the mean nor in the variance  
- A downward trend can be observed  
- Based on the ACF, data seems correlated  


### Checking for Normality (graphically)
```{r}
#Checking for normality graphically
hist(y,prob=T,ylim=c(0,0.15),xlim=c(mean(y)-3*sd(y),mean(y)+3*sd(y)),col="red")
lines(density(y),lwd=2)
mu<-mean(y)
sigma<-sd(y)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- The TS does not appear normally distributed. Data is spread.  

### Graphical exploration (second moment - variance)
```{r}
# C.	Testing for STRICT WHITE NOISE

par(mar=c(1,1,1,1)) # to adjust graphic size
par(mfrow=c(3,1)) # analysis of the squared data
ts.plot(y^2)   
acf(y^2)
pacf(y^2)
```

**Observations**:  
- Based on the ACF of the second moment (variance), there seems to be correlation  

### Computing basic stats
```{r}
mean(y) # compute basic statistics
sd(y)
skewness(y)
kurtosis(y,method=c("moment"))  
```

### Checking for CS
```{r}
# formal unit root test (Augmented Dickey Fuller test). Testing for stationarity.
# Ho: the process is not stationary. We need, at least, a unit root
# H1: the process is stationary. We have to check different models (lags)
ndiffs(y, alpha=0.05, test=c("adf")) # number of regular differences?
```

**Observations**:  
- TS requires transformation to become stationary  
- To make it stationary we need to apply the first difference  

### Checking for Normality
```{r}
# formal normality test
# Ho: the data is normally distributed
# H1: the data is not normally distributed
shapiro.test(y)
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS is not normally distributed   

### Checking for correlation
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test (y, lag = 20, type="Ljung")  # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS is correlated in the mean

### Checking for correlation in the second moment
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test(y^2,lag=20, type="Ljung")    # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS is correlated in the variance


### Transformed data

Applying the formula without defining the difference value
```{r}
# Just in case we need to take one difference to the original data (as in this case)

z<-diff(y)  
ts.plot(z)

par(mfrow=c(3,1))
ts.plot(z)   
acf(z)
pacf(z)
```
**Observations**:  
- TS looks stationary


Checking for CS
```{r}
ndiffs(z, alpha=0.05, test=c("adf")) 
```

**Observations**:  
- Confirmation that no transformation is needed - data is stationary  

checking for normality (graphically)
```{r}
#Checking for normality
hist(z,prob=T,ylim=c(0,0.6),xlim=c(mean(z)-3*sd(z),mean(z)+3*sd(z)),col="red")
lines(density(z),lwd=2)
mu<-mean(z)
sigma<-sd(z)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- Normality is observed


Checking for normality (formal)
```{r}
shapiro.test(z)
```

**Observations**:  
- We accept $H_0$ since $P_{value} > 0.05$, $\therefore$ the TS is normally distributed  

Checking for correlation (first moment - mean)
```{r}
Box.test (z, lag = 20, type="Ljung")
```

**Observations**:  
- We accept $H_0$ since $P_{value} > 0.05$  
- TS is uncorrelated (not correlated) in the mean   
- TS is WN    
- TS is GWN since data is normally distributed    
- TS is SWN since GWN implies SWN   

Checking for correlation (second moment - variance)
```{r}
Box.test (z^2, lag = 20, type="Ljung")
```

**Observations**:  
- We accept $H_0$ since $P_{value} > 0.05$
- TS is uncorrelated (not correlated) in the variance


## Series 3

### Graphical exploration (first moment - mean)

```{r}
y<-series3    # from now, "y" is the data we are going to work with

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # plot the series, its acf and pacf together
ts.plot(y)   
acf(y)
pacf(y)
```
**Observations**:  
- TS shows downward trend
- TS looks no stationary
- TS seems to have correlated data

### Checking for Normality (graphically)
```{r}
#Checking for normality graphically
hist(y,prob=T,ylim=c(0,0.1),xlim=c(mean(y)-3*sd(y),mean(y)+3*sd(y)),col="red")
lines(density(y),lwd=2)
mu<-mean(y)
sigma<-sd(y)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- TS seems not normally distributed


### Graphical exploration (second moment - variance)
```{r}
# C.	Testing for STRICT WHITE NOISE

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # analysis of the squared data
ts.plot(y^2)   
acf(y^2)
pacf(y^2)
```
**Observations**:  
- TS (second moment - variance) shows an upward trend and correlated data


### Computing basic stats

```{r}
mean(y) # compute basic statistics
sd(y)
skewness(y)
kurtosis(y,method=c("moment"))  
```



### Checking for CS

```{r}
# formal unit root test (Augmented Dickey Fuller test). Testing for stationarity.
# Ho: the process is not stationary. We need, at least, a unit root
# H1: the process is stationary. We have to check different models (lags)
ndiffs(y, alpha=0.05, test=c("adf")) # number of regular differences?
```

**Observations**:  
- TS requires transformation to become stationary  
- To make it stationary we need to apply the first difference  

### Checking for Normality
```{r}
# formal normality test
# Ho: the data is normally distributed
# H1: the data is not normally distributed
shapiro.test(y)
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS is not normally distributed  

### Checking for correlation
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test (y, lag = 20, type="Ljung")  # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the mean
- TS is not WN, GWN or SWN
- Linear model possible

### Checking for correlation in the second moment
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test(y^2,lag=20, type="Ljung")    # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the variance  
- Non-linear model may be possible but not needed

### Transformed data

Applying the formula without defining the difference value
```{r}
# Just in case we need to take one difference to the original data (as in this case)

z<-diff(y)  
ts.plot(z)

par(mfrow=c(3,1))
ts.plot(z)   
acf(z)
pacf(z)

ndiffs(z, alpha=0.05, test=c("adf"))

Box.test (z, lag = 20, type="Ljung") 

Box.test (z^2, lag = 20, type="Ljung") 

#Checking for normality

shapiro.test(z)

hist(z,prob=T,ylim=c(0,0.6),xlim=c(mean(z)-3*sd(z),mean(z)+3*sd(z)),col="red")
lines(density(z),lwd=2)
mu<-mean(z)
sigma<-sd(z)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- TS is stationary (constant mean and variance across time). No more transformations are needed.    
- TS data is normally distributed since we accept $H_0$ given that $P_{value} > 0.05$  
- TS is correlated in the mean or variance since we reject $H_0$ for both given that $P_{value} < 0.05$, $\therefore$ TS is not WN, GWN or SWN  
- Linear model possible. Also, a non-linear one but not needed.


## Series 4

### Graphical exploration (first moment - mean)

```{r}
y<-series4    # from now, "y" is the data we are going to work with

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # plot the series, its acf and pacf together
ts.plot(y)   
acf(y)
pacf(y)
```

**Observations**:  
- TS shows upward trend
- TS shows correlation in data  

### Checking for Normality (graphically)
```{r}
#Checking for normality graphically
hist(y,prob=T,ylim=c(0,0.6),xlim=c(mean(y)-3*sd(y),mean(y)+3*sd(y)),col="red")
lines(density(y),lwd=2)
mu<-mean(y)
sigma<-sd(y)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- TS not normally distributed  

### Graphical exploration (second moment - variance)
```{r}
# C.	Testing for STRICT WHITE NOISE

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # analysis of the squared data
ts.plot(y^2)   
acf(y^2)
pacf(y^2)
```

**Observations**:  
- TS shows an upward trend and correlated data in the variance


### Computing basic stats

```{r}

mean(y) # compute basic statistics
sd(y)
skewness(y)
kurtosis(y,method=c("moment"))  
```

**Observations**:  
- bla

### Checking for CS

```{r}
# formal unit root test (Augmented Dickey Fuller test). Testing for stationarity.
# Ho: the process is not stationary. We need, at least, a unit root
# H1: the process is stationary. We have to check different models (lags)
ndiffs(y, alpha=0.05, test=c("adf")) # number of regular differences?
```

**Observations**:  
- TS requires two differences to become stationary


### Checking for Normality
```{r}
# formal normality test
# Ho: the data is normally distributed
# H1: the data is not normally distributed
shapiro.test(y)
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS is not normally distributed  

### Checking for correlation
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test (y, lag = 20, type="Ljung")  # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the mean
- TS is not WN or GWN

### Checking for correlation in the second moment
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test(y^2,lag=20, type="Ljung")    # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the variance
- TS is not SWN for the first and second moments. We do not know if SWN for others but we do not care.  

### Transformed data

Applying the formula defining the difference value = 2
```{r}
# Just in case we need to take one difference to the original data (as in this case)

z<-diff(y, difference = 2)  
ts.plot(z)

par(mfrow=c(3,1))
ts.plot(z)   
acf(z)
pacf(z)
```
**Observations**:  
- TS looks stationary
- TS shows correlated data  


Checking for CS
```{r}
ndiffs(z, alpha=0.05, test=c("adf")) 
```

**Observations**:  
- Confirmation that no transformation is needed - data is stationary  

checking for normality (graphically)
```{r}
#Checking for normality
hist(z,prob=T,ylim=c(0,0.6),xlim=c(mean(z)-3*sd(z),mean(z)+3*sd(z)),col="red")
lines(density(z),lwd=2)
mu<-mean(z)
sigma<-sd(z)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- Normality is observed


Checking for normality (formal)
```{r}
shapiro.test(z)
```

**Observations**:  
- We accept $H_0$ since $P_{value} > 0.05$, $\therefore$ the TS is normally distributed  

Checking for correlation (first moment - mean)
```{r}
Box.test (z, lag = 20, type="Ljung")
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$    
- TS is correlated in the mean    
- TS is not WN, GWN or SWN    

Checking for correlation (second moment - variance)
```{r}
Box.test (z^2, lag = 20, type="Ljung")
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$  
- TS is correlated in the variance


## Series 5

### Graphical exploration (first moment - mean)

```{r}
y<-series5    # from now, "y" is the data we are going to work with

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # plot the series, its acf and pacf together
ts.plot(y)   
acf(y)
pacf(y)
```
**Observations**:  
- TS seems stationary and a bit correlated  

### Checking for Normality (graphically)
```{r}
#Checking for normality graphically
hist(y,prob=T,ylim=c(0,0.6),xlim=c(mean(y)-3*sd(y),mean(y)+3*sd(y)),col="red")
lines(density(y),lwd=2)
mu<-mean(y)
sigma<-sd(y)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- TS appears normal

### Graphical exploration (second moment - variance)
```{r}
# C.	Testing for STRICT WHITE NOISE

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # analysis of the squared data
ts.plot(y^2)   
acf(y^2)
pacf(y^2)
```
**Observations**:  
- TS (second moment) appears correlated  

### Computing basic stats

```{r}
mean(y) # compute basic statistics
sd(y)
skewness(y)
kurtosis(y,method=c("moment"))  
```

### Checking for CS

```{r}
# formal unit root test (Augmented Dickey Fuller test). Testing for stationarity.
# Ho: the process is not stationary. We need, at least, a unit root
# H1: the process is stationary. We have to check different models (lags)
ndiffs(y, alpha=0.05, test=c("adf")) # number of regular differences?
```

**Observations**:  
- Confirmation of CS


### Checking for Normality
```{r}
# formal normality test
# Ho: the data is normally distributed
# H1: the data is not normally distributed
shapiro.test(y)
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS is not normally distributed  

### Checking for correlation
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test (y, lag = 20, type="Ljung")  # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the mean  
- No WN, GWN or SWN  

### Checking for correlation in the second moment
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test(y^2,lag=20, type="Ljung")    # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the variance  

## Series 6

### Graphical exploration (first moment - mean)

```{r}
y<-series6    # from now, "y" is the data we are going to work with

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # plot the series, its acf and pacf together
ts.plot(y)   
acf(y)
pacf(y)
```

**Observations**:  
- TS seems stationary and correlated  


### Checking for Normality (graphically)
```{r}
#Checking for normality graphically
hist(y,prob=T,ylim=c(0,0.6),xlim=c(mean(y)-3*sd(y),mean(y)+3*sd(y)),col="red")
lines(density(y),lwd=2)
mu<-mean(y)
sigma<-sd(y)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- TS seems normally distributed  

### Graphical exploration (second moment - variance)
```{r}
# C.	Testing for STRICT WHITE NOISE

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # analysis of the squared data
ts.plot(y^2)   
acf(y^2)
pacf(y^2)
```

**Observations**:  
- TS seems stationary and correlated  

### Computing basic stats

```{r}
mean(y) # compute basic statistics
sd(y)
skewness(y)
kurtosis(y,method=c("moment"))  
```

### Checking for CS

```{r}
# formal unit root test (Augmented Dickey Fuller test). Testing for stationarity.
# Ho: the process is not stationary. We need, at least, a unit root
# H1: the process is stationary. We have to check different models (lags)
ndiffs(y, alpha=0.05, test=c("adf")) # number of regular differences?
```

**Observations**:  
- TS is stationary  


### Checking for Normality
```{r}
# formal normality test
# Ho: the data is normally distributed
# H1: the data is not normally distributed
shapiro.test(y)
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS is not normally distributed  

### Checking for correlation
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test (y, lag = 20, type="Ljung")  # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the mean   
- TS is not WN, GWN or SWN    
- Linear model possible. Also, non-linear model possible but not needed.

### Checking for correlation in the second moment
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test(y^2,lag=20, type="Ljung")    # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the variance  

## Series 7

### Graphical exploration (first moment - mean)

```{r}
y<-series7    # from now, "y" is the data we are going to work with

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # plot the series, its acf and pacf together
ts.plot(y)   
acf(y)
pacf(y)
```

**Observations**:  
- TS seems not stationary since mean is not constant across time  
- TS the variance seems to be different across time  
- TS has correlated data  

### Checking for Normality (graphically)
```{r}
#Checking for normality graphically
hist(y,prob=T,ylim=c(0,0.1),xlim=c(mean(y)-3*sd(y),mean(y)+3*sd(y)),col="red")
lines(density(y),lwd=2)
mu<-mean(y)
sigma<-sd(y)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- TS seems not normally distributed  

### Graphical exploration (second moment - variance)
```{r}
# C.	Testing for STRICT WHITE NOISE

par(mar=c(1,1,1,1)) # to adjust graphic size

par(mfrow=c(3,1)) # analysis of the squared data
ts.plot(y^2)   
acf(y^2)
pacf(y^2)
```

**Observations**:  
- TS does not seem stationary in the variance
- TS seems correlated


### Computing basic stats

```{r}

mean(y) # compute basic statistics
sd(y)
skewness(y)
kurtosis(y,method=c("moment"))  
```

### Checking for CS

```{r}
# formal unit root test (Augmented Dickey Fuller test). Testing for stationarity.
# Ho: the process is not stationary. We need, at least, a unit root
# H1: the process is stationary. We have to check different models (lags)
ndiffs(y, alpha=0.05, test=c("adf")) # number of regular differences?
```

**Observations**:  
- TS needs transformation (difference operator = 1). Meaning that we need to take the first difference in order to make it stationary.  

### Checking for Normality
```{r}
# formal normality test
# Ho: the data is normally distributed
# H1: the data is not normally distributed
shapiro.test(y)
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS is not normally distributed  

### Checking for correlation
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test (y, lag = 20, type="Ljung")  # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the mean
- TS is not WN, GWN or SWN  
- Linear model possible

### Checking for correlation in the second moment
```{r}
# formal test for white noise (zero autocorrelations)
# Ho: uncorrelated data
# H1: correlated data
Box.test(y^2,lag=20, type="Ljung")    # Null: ro1=.=ro20=0
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS has correlated data in the variance
- Non-linear model possible but not needed.  

### Transformed data

Applying the formula without defining the difference value
```{r}
# Just in case we need to take one difference to the original data (as in this case)

z<-diff(y)  
ts.plot(z)

par(mfrow=c(3,1))
ts.plot(z)   
acf(z)
pacf(z)
```
**Observations**:  
- TS looks stationary


Checking for CS
```{r}
ndiffs(z, alpha=0.05, test=c("adf")) 
```

**Observations**:  
- Confirmation that no transformation is needed - data is stationary  

checking for normality (graphically)
```{r}
#Checking for normality
hist(z,prob=T,ylim=c(0,0.65),xlim=c(mean(z)-3*sd(z),mean(z)+3*sd(z)),col="red")
lines(density(z),lwd=2)
mu<-mean(z)
sigma<-sd(z)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

**Observations**:  
- Normality is observed


Checking for normality (formal)
```{r}
shapiro.test(z)
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$, $\therefore$ the TS is not normally distributed  

Checking for correlation (first moment - mean)
```{r}
Box.test (z, lag = 20, type="Ljung")
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$
- TS is correlated in the mean  
- TS is not WN, GWN or SWN  

Checking for correlation (second moment - variance)
```{r}
Box.test (z^2, lag = 20, type="Ljung")
```

**Observations**:  
- We reject $H_0$ since $P_{value} < 0.05$
- TS is correlated in the variance
